-- 1. Check what catalog/schema the linked server thinks is current
SELECT 
    DB_NAME() AS current_catalog,
    SCHEMA_NAME() AS current_schema
FROM [Databricks_UC]..[information_schema].[tables] 
WHERE TABLE_NAME = 'orders';

-- 2. List available catalogs
SELECT * FROM OPENQUERY(Databricks_UC, 'SHOW CATALOGS');

-- 3. List schemas in your catalog
SELECT * FROM OPENQUERY(Databricks_UC, 'SHOW SCHEMAS IN prod');

-- 4. Confirm table exists
SELECT * FROM OPENQUERY(Databricks_UC, 'SHOW TABLES IN prod.retail');







import requests

# Get token using managed identity or client secret
def get_graph_token():
    # Option A: Managed Identity (no secret needed)
    from azure.identity import DefaultAzureCredential
    credential = DefaultAzureCredential()
    token = credential.get_token("https://graph.microsoft.com/.default").token
    return token

    # Option B: Client Secret (less preferred)
    # client_id, tenant_id, client_secret from Key Vault

token = get_graph_token()

headers = {
    "Authorization": f"Bearer {token}",
    "Content-Type": "application/json"
}

email_data = {
    "message": {
        "subject": "Security Alert from Databricks",
        "body": {"contentType": "Text", "content": "Unauthorized access detected..."},
        "toRecipients": [{"emailAddress": {"address": "manager@yourcompany.com"}}]
    }
}

response = requests.post(
    "https://graph.microsoft.com/v1.0/users/alerts@yourcompany.com/sendMail",
    headers=headers,
    json=email_data
)

print("âœ… Status:", response.status_code)



EXEC sp_addlinkedserver 
    @server = N'Databricks_UC',
    @srvproduct = N'',
    @provider = N'MSDASQL',
    @datasrc = N'Databricks_UC_Prod';


EXEC sp_addlinkedsrvlogin
    @rmtsrvname = N'Databricks_UC',
    @useself = 'False',
    @rmtuser = 'token',                    -- literal word "token"
    @rmtpassword = 'dapiXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX';




UseNativeQuery = 1
