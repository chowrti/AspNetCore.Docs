EXEC sp_addlinkedserver 
    @server = N'Databricks_UC',                -- Linked Server Name
    @srvproduct = N'',
    @provider = N'MSDASQL',                    -- Microsoft OLE DB Provider for ODBC
    @provstr = N'Driver={Databricks Spark ODBC Driver};
                 Host=adb-1234567890123456.7.azuredatabricks.net;
                 Port=443;
                 HTTPPath=/sql/1.0/warehouses/0123456789abcdef0123456789abcdef;
                 AuthMech=3;
                 UID=token;
                 PWD=dapiXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX;
                 ConnCatalog=prod;                 -- ← Default Catalog
                 ConnSchema=retail;                -- ← Default Schema
                 SSL=1;
                 ThriftTransport=2;
                 UseNativeQuery=1';





-- =====================================================
-- List all access events (queries, DML, reads) in last 7 days
-- for selected schemas in Unity Catalog
-- =====================================================

WITH selected_schemas AS (
    SELECT 
        schema_name
    FROM VALUES 
        ('retail'),
        ('gold'),
        ('finance'),
        ('customer') 
        -- ← Add or remove schemas here
    ) AS t(schema_name)
),

parsed_audit AS (
    SELECT 
        event_time,
        user_identity.email AS actor,
        action_name,
        request_params.securable_full_name AS full_object_name,
        request_params.securable_type AS object_type,
        request_params.commandText AS sql_command,
        request_params.operation AS operation,
        source_ip_address,
        request_id,
        
        -- Extract catalog, schema, object
        split(request_params.securable_full_name, '\\.')[0] AS catalog_name,
        CASE WHEN size(split(request_params.securable_full_name, '\\.')) >= 2 
             THEN split(request_params.securable_full_name, '\\.')[1] 
             ELSE NULL END AS schema_name,
        CASE WHEN size(split(request_params.securable_full_name, '\\.')) >= 3 
             THEN split(request_params.securable_full_name, '\\.')[2] 
             ELSE NULL END AS object_name

    FROM system.access.audit
    WHERE service_name = 'unityCatalog'
      AND event_time >= current_timestamp() - INTERVAL 7 DAYS
      AND request_params.securable_full_name IS NOT NULL
      AND action_name IN (
            'executeAdhocQuery', 
            'submitRun', 
            'read', 
            'write', 
            'select',
            'mergeInto', 
            'delete', 
            'updateTable',
            'insertInto'
            'grant', 
            'revoke', 
            'grantPrivilege', 
            'revokePrivilege'
      )
)

SELECT 
    event_time,
    actor,
    action_name,
    catalog_name,
    schema_name,
    object_name,
    object_type,
    full_object_name,
    sql_command,
    operation,
    source_ip_address,
    request_id
FROM parsed_audit
WHERE schema_name IN (SELECT schema_name FROM selected_schemas)
  AND object_type IN ('TABLE', 'VIEW')
ORDER BY event_time DESC;




















-- 1. Check what catalog/schema the linked server thinks is current
SELECT 
    DB_NAME() AS current_catalog,
    SCHEMA_NAME() AS current_schema
FROM [Databricks_UC]..[information_schema].[tables] 
WHERE TABLE_NAME = 'orders';

-- 2. List available catalogs
SELECT * FROM OPENQUERY(Databricks_UC, 'SHOW CATALOGS');

-- 3. List schemas in your catalog
SELECT * FROM OPENQUERY(Databricks_UC, 'SHOW SCHEMAS IN prod');

-- 4. Confirm table exists
SELECT * FROM OPENQUERY(Databricks_UC, 'SHOW TABLES IN prod.retail');







import requests

# Get token using managed identity or client secret
def get_graph_token():
    # Option A: Managed Identity (no secret needed)
    from azure.identity import DefaultAzureCredential
    credential = DefaultAzureCredential()
    token = credential.get_token("https://graph.microsoft.com/.default").token
    return token

    # Option B: Client Secret (less preferred)
    # client_id, tenant_id, client_secret from Key Vault

token = get_graph_token()

headers = {
    "Authorization": f"Bearer {token}",
    "Content-Type": "application/json"
}

email_data = {
    "message": {
        "subject": "Security Alert from Databricks",
        "body": {"contentType": "Text", "content": "Unauthorized access detected..."},
        "toRecipients": [{"emailAddress": {"address": "manager@yourcompany.com"}}]
    }
}

response = requests.post(
    "https://graph.microsoft.com/v1.0/users/alerts@yourcompany.com/sendMail",
    headers=headers,
    json=email_data
)

print("✅ Status:", response.status_code)



EXEC sp_addlinkedserver 
    @server = N'Databricks_UC',
    @srvproduct = N'',
    @provider = N'MSDASQL',
    @datasrc = N'Databricks_UC_Prod';


EXEC sp_addlinkedsrvlogin
    @rmtsrvname = N'Databricks_UC',
    @useself = 'False',
    @rmtuser = 'token',                    -- literal word "token"
    @rmtpassword = 'dapiXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX';




UseNativeQuery = 1
